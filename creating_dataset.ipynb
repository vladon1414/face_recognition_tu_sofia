{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc4f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def normalize_path(path):\n",
    "    \"\"\"Normalize path to remove trailing slashes and ensure forward slashes.\"\"\"\n",
    "    return os.path.normpath(path).replace('\\\\', '/')\n",
    "\n",
    "def validate_paths(df, base_path):\n",
    "    \"\"\"Validate and complete paths in the DataFrame.\"\"\"\n",
    "    invalid_rows = []\n",
    "    folder_images = {}\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # Complete Extracted_Face_Path\n",
    "        id_path = os.path.join(base_path, row['Extracted_Face_Path'])\n",
    "        id_path = normalize_path(id_path)\n",
    "        folder_path = normalize_path(row['Face_Photo_Path'])\n",
    "        \n",
    "        # Validate ID image\n",
    "        if not os.path.isfile(id_path):\n",
    "            logger.warning(f\"ID image not found: {id_path}\")\n",
    "            invalid_rows.append(idx)\n",
    "            continue\n",
    "        \n",
    "        # Validate folder and list images\n",
    "        if not os.path.isdir(folder_path):\n",
    "            logger.warning(f\"Folder not found: {folder_path}\")\n",
    "            invalid_rows.append(idx)\n",
    "            continue\n",
    "        \n",
    "        # Get images in folder (.jpg, .png, .jpeg)\n",
    "        images = [normalize_path(os.path.join(folder_path, f)) \n",
    "                 for f in os.listdir(folder_path) \n",
    "                 if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        \n",
    "        if not images:\n",
    "            logger.warning(f\"No images in folder: {folder_path}\")\n",
    "            invalid_rows.append(idx)\n",
    "            continue\n",
    "        \n",
    "        folder_images[folder_path] = images\n",
    "        df.at[idx, 'Extracted_Face_Path'] = id_path\n",
    "        df.at[idx, 'Face_Photo_Path'] = folder_path\n",
    "    \n",
    "    # Drop invalid rows\n",
    "    if invalid_rows:\n",
    "        logger.info(f\"Dropping {len(invalid_rows)} invalid rows\")\n",
    "        df = df.drop(invalid_rows).reset_index(drop=True)\n",
    "    \n",
    "    # Log folder_images keys for debugging\n",
    "    logger.info(f\"folder_images keys: {list(folder_images.keys())[:5]} (first 5)\")\n",
    "    logger.info(f\"Face_Photo_Path sample: {df['Face_Photo_Path'].head().tolist()}\")\n",
    "    \n",
    "    return df, folder_images\n",
    "\n",
    "def create_true_pairs(df, folder_images):\n",
    "    \"\"\"Create true pairs (ID image vs. person images, label 1).\"\"\"\n",
    "    pairs = []\n",
    "    for idx, row in df.iterrows():\n",
    "        id_path = row['Extracted_Face_Path']\n",
    "        folder_path = row['Face_Photo_Path']\n",
    "        person_images = folder_images.get(folder_path, [])\n",
    "        \n",
    "        if not person_images:\n",
    "            logger.warning(f\"No images found for folder: {folder_path}\")\n",
    "            continue\n",
    "        \n",
    "        for person_img in person_images:\n",
    "            pairs.append({\n",
    "                'id_image_path': id_path,\n",
    "                'person_image_path': person_img,\n",
    "                'label': 1\n",
    "            })\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "def create_false_pairs(df, folder_images, num_false_per_id=5):\n",
    "    \"\"\"Create false pairs (ID image vs. different person's images, label 0).\"\"\"\n",
    "    pairs = []\n",
    "    folder_paths = list(folder_images.keys())\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        id_path = row['Extracted_Face_Path']\n",
    "        current_folder = row['Face_Photo_Path']\n",
    "        \n",
    "        # Select different folders for false pairs\n",
    "        other_folders = [f for f in folder_paths if f != current_folder]\n",
    "        if len(other_folders) < num_false_per_id:\n",
    "            logger.warning(f\"Not enough different folders for ID {row['ID']}, reducing false pairs\")\n",
    "            selected_folders = other_folders\n",
    "        else:\n",
    "            selected_folders = random.sample(other_folders, num_false_per_id)\n",
    "        \n",
    "        for folder in selected_folders:\n",
    "            person_img = random.choice(folder_images[folder])\n",
    "            pairs.append({\n",
    "                'id_image_path': id_path,\n",
    "                'person_image_path': person_img,\n",
    "                'label': 0\n",
    "            })\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    csv_path = r\"D:\\Projects\\PhotosWorkl\\face_id_database.csv\"  # Update if path differs\n",
    "    base_path = r\"D:\\Projects\\PhotosWorkl\"\n",
    "    output_dir = r\"D:\\Projects\\PhotosWorkl\"\n",
    "    num_false_per_id = 5  # Match ~5 true pairs per ID\n",
    "    train_ratio = 0.8\n",
    "    \n",
    "     # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load CSV\n",
    "    logger.info(\"Loading CSV\")\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load CSV: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Validate and complete paths\n",
    "    logger.info(\"Validating paths\")\n",
    "    df, folder_images = validate_paths(df, base_path)\n",
    "    if df.empty:\n",
    "        logger.error(\"No valid data after validation\")\n",
    "        return\n",
    "    \n",
    "    logger.info(f\"Found {len(df)} valid IDs with {sum(len(imgs) for imgs in folder_images.values())} person images\")\n",
    "    \n",
    "    # Create true pairs\n",
    "    logger.info(\"Creating true pairs\")\n",
    "    true_pairs = create_true_pairs(df, folder_images)\n",
    "    if not true_pairs:\n",
    "        logger.error(\"No true pairs generated. Check Face_Photo_Path and folder_images.\")\n",
    "        return\n",
    "    logger.info(f\"Generated {len(true_pairs)} true pairs\")\n",
    "    \n",
    "    # Create false pairs (match number of true pairs)\n",
    "    logger.info(\"Creating false pairs\")\n",
    "    num_false_pairs = len(true_pairs)  # Balance true and false\n",
    "    num_false_per_id = max(1, num_false_pairs // len(df))  # Adjust false pairs per ID\n",
    "    false_pairs = create_false_pairs(df, folder_images, num_false_per_id)\n",
    "    logger.info(f\"Generated {len(false_pairs)} false pairs\")\n",
    "    \n",
    "    # Combine pairs\n",
    "    all_pairs = true_pairs + false_pairs\n",
    "    pairs_df = pd.DataFrame(all_pairs)\n",
    "    logger.info(f\"Total pairs: {len(pairs_df)} (Label 1: {len(pairs_df[pairs_df['label'] == 1])}, Label 0: {len(pairs_df[pairs_df['label'] == 0])})\")\n",
    "    \n",
    "    # Save unified CSV\n",
    "    all_pairs_path = os.path.join(output_dir, 'all_pairs.csv')\n",
    "    pairs_df.to_csv(all_pairs_path, index=False)\n",
    "    logger.info(f\"Saved unified CSV: {all_pairs_path}\")\n",
    "    \n",
    "    # Split into train and test\n",
    "    logger.info(\"Splitting into train and test\")\n",
    "    train_df, test_df = train_test_split(\n",
    "        pairs_df,\n",
    "        test_size=1 - train_ratio,\n",
    "        stratify=pairs_df['label'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Save train and test CSVs\n",
    "    train_path = os.path.join(output_dir, 'train_pairs.csv')\n",
    "    test_path = os.path.join(output_dir, 'test_pairs.csv')\n",
    "    train_df.to_csv(train_path, index=False)\n",
    "    test_df.to_csv(test_path, index=False)\n",
    "    \n",
    "    logger.info(f\"Saved train CSV: {train_path} ({len(train_df)} pairs)\")\n",
    "    logger.info(f\"Saved test CSV: {test_path} ({len(test_df)} pairs)\")\n",
    "    logger.info(f\"Train label distribution: Label 1: {len(train_df[train_df['label'] == 1])}, Label 0: {len(train_df[train_df['label'] == 0])}\")\n",
    "    logger.info(f\"Test label distribution: Label 1: {len(test_df[test_df['label'] == 1])}, Label 0: {len(test_df[test_df['label'] == 0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb0d2e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 18:23:05,187 - INFO - Loading CSV\n",
      "2025-05-21 18:23:05,189 - INFO - Validating paths\n",
      "2025-05-21 18:23:05,311 - INFO - folder_images keys: ['D:/Projects/finalGPT/originals/1159', 'D:/Projects/finalGPT/originals/116', 'D:/Projects/finalGPT/originals/1161', 'D:/Projects/finalGPT/originals/1162', 'D:/Projects/finalGPT/originals/1163'] (first 5)\n",
      "2025-05-21 18:23:05,312 - INFO - Face_Photo_Path sample: ['D:/Projects/finalGPT/originals/1159', 'D:/Projects/finalGPT/originals/116', 'D:/Projects/finalGPT/originals/1161', 'D:/Projects/finalGPT/originals/1162', 'D:/Projects/finalGPT/originals/1163']\n",
      "2025-05-21 18:23:05,312 - INFO - Found 728 valid IDs with 3636 person images\n",
      "2025-05-21 18:23:05,312 - INFO - Creating true pairs\n",
      "2025-05-21 18:23:05,333 - INFO - Generated 3636 true pairs\n",
      "2025-05-21 18:23:05,334 - INFO - Creating false pairs\n",
      "2025-05-21 18:23:05,384 - INFO - Generated 2912 false pairs\n",
      "2025-05-21 18:23:05,389 - INFO - Total pairs: 6548 (Label 1: 3636, Label 0: 2912)\n",
      "2025-05-21 18:23:05,404 - INFO - Saved unified CSV: D:\\Projects\\PhotosWorkl\\all_pairs.csv\n",
      "2025-05-21 18:23:05,405 - INFO - Splitting into train and test\n",
      "2025-05-21 18:23:05,423 - INFO - Saved train CSV: D:\\Projects\\PhotosWorkl\\train_pairs.csv (5238 pairs)\n",
      "2025-05-21 18:23:05,424 - INFO - Saved test CSV: D:\\Projects\\PhotosWorkl\\test_pairs.csv (1310 pairs)\n",
      "2025-05-21 18:23:05,426 - INFO - Train label distribution: Label 1: 2909, Label 0: 2329\n",
      "2025-05-21 18:23:05,427 - INFO - Test label distribution: Label 1: 727, Label 0: 583\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
